{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894982c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance:\n",
      "\n",
      "                     Accuracy  Precision    Recall  F1-score\n",
      "Logistic Regression  0.583333   0.485122  0.583333  0.527275\n",
      "Decision Tree        0.483333   0.477513  0.483333  0.478333\n",
      "Random Forest        0.533333   0.527222  0.533333  0.529464\n",
      "SVM                  0.550000   0.451151  0.550000  0.485017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alaa Farouk\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "columns = [\n",
    "    \"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \n",
    "    \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"\n",
    "]\n",
    "df = pd.read_csv(\"processed.cleveland.data\", header = None, names = columns )\n",
    "\n",
    "one_hot_encoded_cols = ['ca','restecg','cp', 'slope','thal']\n",
    "\n",
    "\n",
    "df = df[~df.isin(['?']).any(axis=1)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "target = df['target']\n",
    "\n",
    "df = df.drop('target',axis = 1)\n",
    "\n",
    "selected_features = ['ca', 'cp', 'oldpeak', 'thal']\n",
    "X = df[selected_features]\n",
    "y= target\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    \"SVM\": SVC(probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "roc_curves = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "\n",
    "    if name in [\"Logistic Regression\", \"SVM\"]:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred,average='weighted')\n",
    "    rec = recall_score(y_test, y_pred,average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred,average='weighted')\n",
    "    #auc_ovr = roc_auc_score(y_test, y_prob, multi_class='ovr', average='weighted')\n",
    "    #auc_ovo = roc_auc_score(y_test, y_prob, multi_class='ovo', average='weighted')\n",
    "    \n",
    "    results[name] = {\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1-score\": f1,\n",
    "        #\"AUC One-vs-Rest:\": auc_ovr,\n",
    "        #\"AUC One-vs-One:\" : auc_ovo\n",
    "    }\n",
    "\n",
    "   # fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "   # roc_curves[name] = (fpr, tpr)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Performance:\\n\")\n",
    "print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14622582",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"evaluation_metrics\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
